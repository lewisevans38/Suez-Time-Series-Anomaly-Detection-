{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9lN7K0RaNtCjZ3C5tYb24",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lewisevans38/Suez-Time-Series-Anomaly-Detection-/blob/main/TADGANonNAB_awscpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aXJ5V-GbL7M"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_09Ls8LNbTuO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, signal_shape=100, latent_space_dim=20, hyperbolic=False):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.signal_shape = signal_shape\n",
        "        self.latent_space_dim = latent_space_dim\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.signal_shape,\n",
        "            hidden_size=50,\n",
        "            num_layers=1,\n",
        "            bidirectional=True,\n",
        "        )\n",
        "        self.dense = nn.Linear(in_features=100, out_features=self.latent_space_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(1, -1, self.signal_shape).float()\n",
        "        x, (hn, cn) = self.lstm(x)\n",
        "        x = self.dense(x)\n",
        "        return x\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, signal_shape=100, latent_space_dim=20, hyperbolic=False):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.signal_shape = signal_shape\n",
        "        self.latent_space_dim = latent_space_dim\n",
        "        self.dense1 = nn.Linear(in_features=self.latent_space_dim, out_features=50)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=50, hidden_size=64, num_layers=2, dropout=0.2, bidirectional=True\n",
        "        )\n",
        "        self.dense2 = nn.Linear(in_features=128, out_features=self.signal_shape)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.hyperbolic = hyperbolic\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dense1(x)\n",
        "        x, (hn, cn) = self.lstm(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "class CriticX(nn.Module):\n",
        "    def __init__(self, signal_shape=10, latent_space_dim=20):\n",
        "        super(CriticX, self).__init__()\n",
        "        self.signal_shape = signal_shape\n",
        "        self.latent_space_dim = latent_space_dim\n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
        "        self.dense1 = nn.Linear(\n",
        "            in_features=self.signal_shape, out_features=self.latent_space_dim\n",
        "        )\n",
        "        self.dense2 = nn.Linear(\n",
        "            in_features=self.latent_space_dim, out_features=self.latent_space_dim\n",
        "        )\n",
        "        self.dense3 = nn.Linear(\n",
        "            in_features=self.latent_space_dim, out_features=self.latent_space_dim\n",
        "        )\n",
        "        self.dense4 = nn.Linear(\n",
        "            in_features=self.latent_space_dim, out_features=self.latent_space_dim\n",
        "        )\n",
        "        self.dense5 = nn.Linear(in_features=self.latent_space_dim, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(1, -1, self.signal_shape).float()\n",
        "        x = self.dense1(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense3(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense4(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense5(x)\n",
        "        return x\n",
        "class CriticZ(nn.Module):\n",
        "    def __init__(self, latent_space_dim=20):\n",
        "        super(CriticZ, self).__init__()\n",
        "        self.latent_space_dim = latent_space_dim\n",
        "        self.dense1 = nn.Linear(\n",
        "            in_features=self.latent_space_dim, out_features=self.latent_space_dim\n",
        "        )\n",
        "        self.dense2 = nn.Linear(\n",
        "            in_features=self.latent_space_dim, out_features=self.latent_space_dim\n",
        "        )\n",
        "        self.dense3 = nn.Linear(in_features=self.latent_space_dim, out_features=1)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dense1(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def unroll_signal(self, x):\n",
        "    x = np.array(x).reshape(100)\n",
        "    return np.median(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O8jvQBub0qW"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad as torch_grad\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kUTZ4qJbnAg"
      },
      "outputs": [],
      "source": [
        "def critic_x_iteration(sample, decoder, critic_x, optim_cx, TIME_STEPS):\n",
        "    optim_cx.zero_grad()\n",
        "    y = sample.view(1, 1, TIME_STEPS)\n",
        "    valid_x = torch.squeeze(critic_x(y))\n",
        "\n",
        "    # The sampled z are the anomalous points - points deviating from actual distribution of z (obtained through encoding x)\n",
        "    latent_space_dim = 45\n",
        "    z = torch.Tensor(\n",
        "        np.random.normal(size=(1, 1,latent_space_dim))\n",
        "    )\n",
        "    x_ = decoder(z)\n",
        "\n",
        "    fake_x = torch.squeeze(critic_x(x_))\n",
        "\n",
        "    critic_score_valid_x = torch.mean(\n",
        "        -torch.ones(valid_x.shape) * valid_x\n",
        "    )  # Wasserstein Loss\n",
        "    critic_score_fake_x = torch.mean(\n",
        "        torch.ones(fake_x.shape) * fake_x\n",
        "    )  # Wasserstein Loss\n",
        "\n",
        "    real_data = y\n",
        "    generated_data = x_\n",
        "\n",
        "    batch_size_ = real_data.size()[0]\n",
        "\n",
        "    # Calculate interpolation\n",
        "    alpha = torch.rand(y.shape)\n",
        "    alpha = alpha.expand_as(real_data)\n",
        "    alpha = alpha\n",
        "    interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n",
        "    interpolated = Variable(interpolated, requires_grad=True)\n",
        "    interpolated = interpolated\n",
        "\n",
        "    # Calculate probability of interpolated examples\n",
        "    prob_interpolated = critic_x(interpolated)\n",
        "\n",
        "    # Calculate gradients of probabilities with respect to examples\n",
        "    gradients = torch_grad(\n",
        "        outputs=prob_interpolated,\n",
        "        inputs=interpolated,\n",
        "        grad_outputs=torch.ones(prob_interpolated.size()),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "\n",
        "    # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
        "    # so flatten to easily take norm per example in batch\n",
        "    gradients = gradients.view(batch_size_, -1)\n",
        "    # self.losses['gradient_norm'].append(gradients.norm(2, dim=1).mean().data[0])\n",
        "\n",
        "    # Derivatives of the gradient close to 0 can cause problems because of\n",
        "    # the square root, so manually calculate norm and add epsilon\n",
        "    gradients_norm = torch.sqrt(torch.sum(gradients**2, dim=1) + 1e-12)\n",
        "\n",
        "    # Return gradient penalty\n",
        "    gp_loss = ((gradients_norm - 1) ** 2).mean()\n",
        "\n",
        "    #################################################\n",
        "\n",
        "    # Critic has to maximize Cx(Valid X) - Cx(Fake X).\n",
        "    # Maximizing the above is same as minimizing the negative.\n",
        "    wl = critic_score_fake_x + critic_score_valid_x\n",
        "    loss = wl + 10 * gp_loss\n",
        "    loss.backward(retain_graph=True)\n",
        "    optim_cx.step()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS1Uz4sJcJCB"
      },
      "outputs": [],
      "source": [
        "def critic_z_iteration(sample, encoder, critic_z, optim_cz, TIME_STEPS):\n",
        "    optim_cz.zero_grad()\n",
        "\n",
        "    x = sample.view(1, 1, TIME_STEPS)\n",
        "    z_ = encoder(x)\n",
        "\n",
        "    fake_z = torch.squeeze(critic_z(z_))\n",
        "    critic_score_fake_z = torch.mean(\n",
        "        torch.ones(fake_z.shape)* fake_z\n",
        "    )  # Wasserstein Loss\n",
        "\n",
        "\n",
        "    latent_space_dim = 45\n",
        "    z = torch.Tensor(\n",
        "        np.random.normal(size=(1,1, latent_space_dim))\n",
        "    )\n",
        "    valid_z = torch.squeeze(critic_z(z))\n",
        "    critic_score_valid_z = torch.mean(\n",
        "        -torch.ones(fake_z.shape) * valid_z\n",
        "    )  # Wasserstein Loss\n",
        "\n",
        "    wl = critic_score_fake_z + critic_score_valid_z\n",
        "\n",
        "    real_data = z\n",
        "    generated_data = z_\n",
        "\n",
        "    batch_size_ = real_data.size()[0]\n",
        "\n",
        "    # Calculate interpolation\n",
        "    alpha = torch.rand(z.shape)\n",
        "    alpha = alpha.expand_as(real_data)\n",
        "    interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n",
        "    interpolated = Variable(interpolated, requires_grad=True)\n",
        "    interpolated = interpolated\n",
        "\n",
        "    # Calculate probability of interpolated examples\n",
        "    prob_interpolated = critic_z(interpolated)\n",
        "\n",
        "    # Calculate gradients of probabilities with respect to examples\n",
        "    gradients = torch_grad(\n",
        "        outputs=prob_interpolated,\n",
        "        inputs=interpolated,\n",
        "        grad_outputs=torch.ones(prob_interpolated.size()),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "\n",
        "    # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
        "    # so flatten to easily take norm per example in batch\n",
        "    gradients = gradients.view(batch_size_, -1)\n",
        "    # self.losses['gradient_norm'].append(gradients.norm(2, dim=1).mean().data[0])\n",
        "\n",
        "    # Derivatives of the gradient close to 0 can cause problems because of\n",
        "    # the square root, so manually calculate norm and add epsilon\n",
        "    gradients_norm = torch.sqrt(torch.sum(gradients**2, dim=1) + 1e-12)\n",
        "\n",
        "    # Return gradient penalty\n",
        "    gp_loss = ((gradients_norm - 1) ** 2).mean()\n",
        "\n",
        "    #################################################\n",
        "\n",
        "    loss = wl + 10 * gp_loss\n",
        "    loss.backward(retain_graph=True)\n",
        "    optim_cz.step()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTWhu6XWcVBY"
      },
      "outputs": [],
      "source": [
        "def decoder_iteration(\n",
        "    sample,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    critic_x,\n",
        "    critic_z,\n",
        "    optim_dec,\n",
        "    TIME_STEPS,\n",
        "    err_loss=nn.MSELoss(),\n",
        "):\n",
        "    optim_dec.zero_grad()\n",
        "\n",
        "    x_gen = sample.view(1, 1, TIME_STEPS)\n",
        "    z_gen_ = encoder(x_gen)\n",
        "    fake_gen_z = critic_z(z_gen_)\n",
        "\n",
        "    latent_space_dim = 45\n",
        "    z_gen = torch.Tensor(\n",
        "        np.random.normal(size=(1, 1, latent_space_dim))\n",
        "    )\n",
        "\n",
        "\n",
        "    x_gen_ = decoder(z_gen)\n",
        "\n",
        "\n",
        "    fake_gen_x = critic_x(x_gen_)\n",
        "    critic_score_fake_gen_x = torch.mean(\n",
        "        -torch.ones(fake_gen_x.shape) * fake_gen_x\n",
        "    )\n",
        "    critic_score_fake_gen_z = torch.mean(\n",
        "        -torch.ones(fake_gen_z.shape) * fake_gen_z\n",
        "    )\n",
        "\n",
        "    x_gen_rec = decoder(z_gen_)\n",
        "    mse_loss = err_loss(x_gen.float(), x_gen_rec.float())\n",
        "    loss_dec = 10 * mse_loss + critic_score_fake_gen_x + critic_score_fake_gen_z\n",
        "\n",
        "    loss_dec.backward()\n",
        "    optim_dec.step()\n",
        "\n",
        "    return loss_dec, 0, mse_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY1VzRHYcrWQ"
      },
      "outputs": [],
      "source": [
        "def train_tadgan(\n",
        "    train_dataset1,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    critic_x,\n",
        "    critic_z,\n",
        "    n_epochs=2000,\n",
        "    TIME_STEPS = 0,\n",
        "):\n",
        "    cx_epoch_loss = list()\n",
        "    cz_epoch_loss = list()\n",
        "    encoder_epoch_loss = list()\n",
        "    decoder_epoch_loss = list()\n",
        "    hyp_dec_loss = list()\n",
        "    eucl_dec_loss = list()\n",
        "\n",
        "    \"\"\"\n",
        "    INIT OPTIMIZERS\n",
        "    \"\"\"\n",
        "    # optim_enc = optim.Adam(encoder.parameters(), lr=params.lr, betas=(0.9, 0.999))\n",
        "    optim_cx = optim.Adam(critic_x.parameters(), lr=1e-6, betas=(0.9, 0.999))\n",
        "    optim_cz = optim.Adam(critic_z.parameters(), lr=1e-6, betas=(0.9, 0.999))\n",
        "    # optim_dec = optim.Adam(decoder.parameters(), lr=params.lr, betas=(0.9, 0.999))\n",
        "    optim_dec = optim.Adam(\n",
        "        list(decoder.parameters()) + list(encoder.parameters()),\n",
        "        lr=1e-6,\n",
        "        betas=(0.9, 0.999),\n",
        "    )\n",
        "    actual_epoch = 0\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    TRAINING LOOP\n",
        "    \"\"\"\n",
        "    for epoch in range(n_epochs):\n",
        "        n_critics = 5\n",
        "\n",
        "        cx_nc_loss = list()\n",
        "        cz_nc_loss = list()\n",
        "\n",
        "        for param in decoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in critic_x.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in critic_z.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        for i in range(n_critics):\n",
        "            cx_loss = list()\n",
        "            cz_loss = list()\n",
        "\n",
        "            for sample in train_dataset1:\n",
        "                loss = critic_x_iteration(\n",
        "                    sample, decoder, critic_x, optim_cx, TIME_STEPS= TIME_STEPS\n",
        "                )\n",
        "                cx_loss.append(loss)\n",
        "\n",
        "                loss = critic_z_iteration(\n",
        "                    sample, encoder, critic_z, optim_cz, TIME_STEPS = TIME_STEPS\n",
        "                )\n",
        "                cz_loss.append(loss)\n",
        "\n",
        "            cx_nc_loss.append(torch.mean(torch.tensor(cx_loss)))\n",
        "            cz_nc_loss.append(torch.mean(torch.tensor(cz_loss)))\n",
        "\n",
        "        for param in decoder.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in encoder.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in critic_x.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in critic_z.parameters():\n",
        "            param.requires_grad = False\n",
        "        encoder_loss = list()\n",
        "        decoder_loss = list()\n",
        "        hyp_loss = list()\n",
        "        mse_losss = list()\n",
        "        for sample in train_dataset1:\n",
        "            # enc_loss = encoder_iteration(sample.cuda())\n",
        "            dec_loss, hyper_loss, mse_loss = decoder_iteration(\n",
        "                sample, encoder, decoder, critic_x, critic_z, optim_dec,TIME_STEPS)\n",
        "            # encoder_loss.append(enc_loss)\n",
        "            decoder_loss.append(dec_loss)\n",
        "            # type: ignore\n",
        "            mse_losss.append(mse_loss.float())\n",
        "\n",
        "        cx_epoch_loss.append(torch.mean(torch.tensor(cx_nc_loss)))\n",
        "        cz_epoch_loss.append(torch.mean(torch.tensor(cz_nc_loss)))\n",
        "        # encoder_epoch_loss.append(torch.mean(torch.tensor(encoder_loss)))\n",
        "        decoder_epoch_loss.append(torch.mean(torch.tensor(decoder_loss)))\n",
        "\n",
        "        eucl_dec_loss.append(torch.mean(torch.tensor(mse_losss)))\n",
        "\n",
        "        print(\"Encoder decoder training done in epoch {}\".format(epoch))\n",
        "\n",
        "\n",
        "        print(\"Eucl mse loss {}\".format(eucl_dec_loss[-1]))\n",
        "        print(\n",
        "            \"critic x loss {:.3f} critic z loss {:.3f} \\ndecoder loss {:.3f}\\n\".format(\n",
        "                cx_epoch_loss[-1], cz_epoch_loss[-1], decoder_epoch_loss[-1]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        actual_epoch += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSfhdQ7qdG2q"
      },
      "outputs": [],
      "source": [
        "def train1(epochs, train_loader, TIME_STEPS):\n",
        "    \"\"\"\n",
        "    MODEL INITIALIZATION\n",
        "    \"\"\"\n",
        "    latent_space_dim = 45\n",
        "    print(\"w\")\n",
        "    encoder = (\n",
        "        Encoder(TIME_STEPS, latent_space_dim).train()\n",
        "    )\n",
        "    decoder = (\n",
        "       Decoder(TIME_STEPS, latent_space_dim,)\n",
        "\n",
        "        .train()\n",
        "    )\n",
        "    critic_x = (\n",
        "       CriticX(TIME_STEPS, latent_space_dim).train()\n",
        "    )\n",
        "    critic_z =CriticZ(latent_space_dim).train()\n",
        "\n",
        "    \"\"\"\n",
        "    TRAIN\n",
        "    \"\"\"\n",
        "    train_tadgan(\n",
        "        train_loader,\n",
        "        encoder,\n",
        "        decoder,\n",
        "        critic_x,\n",
        "        critic_z,\n",
        "        n_epochs=epochs,\n",
        "        TIME_STEPS = TIME_STEPS\n",
        "    )\n",
        "    return encoder, decoder, critic_x, critic_z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvWUcXbplQCf"
      },
      "source": [
        "All of this code has come from the following github https://github.com/aleflabo/HypAD/blob/main/main.py, who are people that try to improve upon the TadGAN. I intend to only use the TadGAN section, so I have removed the hyperbolic additions where neccesary. I have also made changes so that the code can work with my specific dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAnKsahln_tj",
        "outputId": "11d06936-8fa7-48f1-b812-5e7479c8f2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3830, 2) (202, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-70e85bc28990>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train['value'] = scaler.transform(train[['value']])\n",
            "<ipython-input-9-70e85bc28990>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test['value'] = scaler.transform(test[['value']])\n"
          ]
        }
      ],
      "source": [
        "URL1= \"https://raw.githubusercontent.com/numenta/NAB/master/data/realAWSCloudwatch/ec2_cpu_utilization_24ae8d.csv\"\n",
        "DATA1 = pd.read_csv(URL1)\n",
        "\n",
        "DATA1 = pd.read_csv(URL1)\n",
        "df  = DATA1\n",
        "\n",
        "train_size = int(len(df) * 0.95)\n",
        "test_size = len(df) - train_size\n",
        "train, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]\n",
        "print(train.shape, test.shape)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range =(-1,1))\n",
        "scaler = scaler.fit(train[['value']])\n",
        "train['value'] = scaler.transform(train[['value']])\n",
        "test['value'] = scaler.transform(test[['value']])\n",
        "df['value'] = scaler.transform(df[['value']])\n",
        "\n",
        "def create_dataset(X, y, time_steps):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        v = X.iloc[i:(i + time_steps)].values\n",
        "        Xs.append(v)\n",
        "        ys.append(y.iloc[i + time_steps])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "TIME_STEPS = 6\n",
        "# reshape to [samples, time_steps, n_features]\n",
        "X_train, y_train = create_dataset(\n",
        "  train[['value']],\n",
        "  train.value,\n",
        "  TIME_STEPS\n",
        ")\n",
        "X_test, y_test = create_dataset(\n",
        "  test[['value']],\n",
        "  test.value,\n",
        "  TIME_STEPS\n",
        ")\n",
        "\n",
        "##Turn into pytorch tensors\n",
        "X_train = torch.tensor(X_train).float()\n",
        "y_train = torch.tensor(y_train).float()\n",
        "X_test = torch.tensor(X_test).float()\n",
        "y_test = torch.tensor(y_test).float()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iafo4G71o-V1",
        "outputId": "490dfbff-ea92-4387-b502-45aa135ff521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w\n",
            "Encoder decoder training done in epoch 0\n",
            "Eucl mse loss 0.8878694772720337\n",
            "critic x loss 8.971 critic z loss 7.178 \n",
            "decoder loss 8.936\n",
            "\n",
            "Encoder decoder training done in epoch 1\n",
            "Eucl mse loss 0.8290820717811584\n",
            "critic x loss 6.292 critic z loss 4.918 \n",
            "decoder loss 8.339\n",
            "\n",
            "Encoder decoder training done in epoch 2\n",
            "Eucl mse loss 0.7520548105239868\n",
            "critic x loss 1.874 critic z loss 2.128 \n",
            "decoder loss 7.484\n",
            "\n",
            "Encoder decoder training done in epoch 3\n",
            "Eucl mse loss 0.638180136680603\n",
            "critic x loss 0.469 critic z loss 0.783 \n",
            "decoder loss 6.152\n",
            "\n",
            "Encoder decoder training done in epoch 4\n",
            "Eucl mse loss 0.4580235779285431\n",
            "critic x loss 0.231 critic z loss 0.731 \n",
            "decoder loss 4.210\n",
            "\n",
            "Encoder decoder training done in epoch 5\n",
            "Eucl mse loss 0.2313985377550125\n",
            "critic x loss 0.037 critic z loss 0.779 \n",
            "decoder loss 1.823\n",
            "\n",
            "Encoder decoder training done in epoch 6\n",
            "Eucl mse loss 0.07374793291091919\n",
            "critic x loss -0.085 critic z loss 0.755 \n",
            "decoder loss 0.104\n",
            "\n",
            "Encoder decoder training done in epoch 7\n",
            "Eucl mse loss 0.020260602235794067\n",
            "critic x loss -0.117 critic z loss 0.763 \n",
            "decoder loss -0.589\n",
            "\n",
            "Encoder decoder training done in epoch 8\n",
            "Eucl mse loss 0.008666918613016605\n",
            "critic x loss -0.149 critic z loss 0.731 \n",
            "decoder loss -0.823\n",
            "\n",
            "Encoder decoder training done in epoch 9\n",
            "Eucl mse loss 0.00694828387349844\n",
            "critic x loss -0.157 critic z loss 0.670 \n",
            "decoder loss -0.876\n",
            "\n",
            "Encoder decoder training done in epoch 10\n",
            "Eucl mse loss 0.00706595741212368\n",
            "critic x loss -0.153 critic z loss 0.548 \n",
            "decoder loss -0.873\n",
            "\n",
            "Encoder decoder training done in epoch 11\n",
            "Eucl mse loss 0.0074876463040709496\n",
            "critic x loss -0.133 critic z loss 0.325 \n",
            "decoder loss -0.807\n",
            "\n",
            "Encoder decoder training done in epoch 12\n",
            "Eucl mse loss 0.007830760441720486\n",
            "critic x loss -0.091 critic z loss 0.067 \n",
            "decoder loss -0.711\n",
            "\n",
            "Encoder decoder training done in epoch 13\n",
            "Eucl mse loss 0.008050080388784409\n",
            "critic x loss -0.056 critic z loss -0.254 \n",
            "decoder loss -0.634\n",
            "\n",
            "Encoder decoder training done in epoch 14\n",
            "Eucl mse loss 0.008118944242596626\n",
            "critic x loss -0.035 critic z loss -0.617 \n",
            "decoder loss -0.543\n",
            "\n",
            "Encoder decoder training done in epoch 15\n",
            "Eucl mse loss 0.00802832841873169\n",
            "critic x loss 0.014 critic z loss -1.005 \n",
            "decoder loss -0.449\n",
            "\n",
            "Encoder decoder training done in epoch 16\n",
            "Eucl mse loss 0.0078087616711854935\n",
            "critic x loss 0.060 critic z loss -1.380 \n",
            "decoder loss -0.394\n",
            "\n",
            "Encoder decoder training done in epoch 17\n",
            "Eucl mse loss 0.007523682434111834\n",
            "critic x loss 0.100 critic z loss -1.752 \n",
            "decoder loss -0.349\n",
            "\n",
            "Encoder decoder training done in epoch 18\n",
            "Eucl mse loss 0.007357076741755009\n",
            "critic x loss 0.133 critic z loss -2.102 \n",
            "decoder loss -0.312\n",
            "\n",
            "Encoder decoder training done in epoch 19\n",
            "Eucl mse loss 0.007428194396197796\n",
            "critic x loss 0.179 critic z loss -2.375 \n",
            "decoder loss -0.305\n",
            "\n",
            "Encoder decoder training done in epoch 20\n",
            "Eucl mse loss 0.007615101523697376\n",
            "critic x loss 0.199 critic z loss -2.582 \n",
            "decoder loss -0.324\n",
            "\n",
            "Encoder decoder training done in epoch 21\n",
            "Eucl mse loss 0.007622961420565844\n",
            "critic x loss 0.236 critic z loss -2.729 \n",
            "decoder loss -0.348\n",
            "\n",
            "Encoder decoder training done in epoch 22\n",
            "Eucl mse loss 0.007404830306768417\n",
            "critic x loss 0.270 critic z loss -2.835 \n",
            "decoder loss -0.422\n",
            "\n",
            "Encoder decoder training done in epoch 23\n",
            "Eucl mse loss 0.007283513434231281\n",
            "critic x loss 0.293 critic z loss -2.884 \n",
            "decoder loss -0.520\n",
            "\n",
            "Encoder decoder training done in epoch 24\n",
            "Eucl mse loss 0.007298831362277269\n",
            "critic x loss 0.305 critic z loss -2.915 \n",
            "decoder loss -0.674\n",
            "\n",
            "Encoder decoder training done in epoch 25\n",
            "Eucl mse loss 0.007479456719011068\n",
            "critic x loss 0.334 critic z loss -2.880 \n",
            "decoder loss -0.783\n",
            "\n",
            "Encoder decoder training done in epoch 26\n",
            "Eucl mse loss 0.0077584837563335896\n",
            "critic x loss 0.347 critic z loss -2.891 \n",
            "decoder loss -0.930\n",
            "\n",
            "Encoder decoder training done in epoch 27\n",
            "Eucl mse loss 0.008116173557937145\n",
            "critic x loss 0.344 critic z loss -2.880 \n",
            "decoder loss -1.091\n",
            "\n",
            "Encoder decoder training done in epoch 28\n",
            "Eucl mse loss 0.008461670950055122\n",
            "critic x loss 0.369 critic z loss -2.897 \n",
            "decoder loss -1.264\n",
            "\n",
            "Encoder decoder training done in epoch 29\n",
            "Eucl mse loss 0.008748031221330166\n",
            "critic x loss 0.401 critic z loss -2.877 \n",
            "decoder loss -1.406\n",
            "\n"
          ]
        }
      ],
      "source": [
        "e, d, cx, cz = train1(30, X_train, TIME_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBT8bQOjtJEL"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "with torch.no_grad():\n",
        "  for seq_true in X_train:\n",
        "    predictions.append(d(e(seq_true))[:][0][0][-1].item())\n",
        "  for seq_true in X_test:\n",
        "    predictions.append(d(e(seq_true))[:][0][0][-1].item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd8n7tKHtol8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SlV2P32uplp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "dad41503-4f34-486e-8d91-258e5710e8a6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(df['value'], label = 'Actual')\n",
        "plt.plot(predictions, label ='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the anomaly detection mechanism. The idea is to find pointwise-difference reconstruction errors, as well as compute a critic score for each sequence."
      ],
      "metadata": {
        "id": "Flfcw5aAYBLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Seeing how the model predicts on the anomalous data sets.\n",
        "##Creating Datasets\n",
        "\n",
        "##Predictions\n",
        "critic_score = []\n",
        "\n",
        "##Computing critic score for each sequence\n",
        "with torch.no_grad():\n",
        "  for seq_true in X_train:\n",
        "    critic_score.append(cx(seq_true))\n",
        "  for seq_true in X_test:\n",
        "    critic_score.append(cx(seq_true))"
      ],
      "metadata": {
        "id": "39ipkHeHsOeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Computing pointwise difference Xc\n",
        "indextracker = []\n",
        "difference = []\n",
        "for x in range(0,len(predictions)):\n",
        "  diff = abs(df['value'][x] - predictions[x])\n",
        "  difference.append(diff)\n"
      ],
      "metadata": {
        "id": "db3bqYSQsMGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "Z_RE = stats.zscore(difference)\n",
        "Z_cx = stats.zscore(critic_score)\n",
        "\n",
        "#taking z_scores"
      ],
      "metadata": {
        "id": "yy9x9GOItEPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_errors = []\n",
        "for x in range(len(Z_RE)):\n",
        "  true_errors.append(abs(Z_RE[x]*Z_cx[x]))\n",
        "\n",
        "standard_deviation = np.std(true_errors)\n",
        "Mean = np.mean(true_errors)\n",
        "for x in range (0,len(true_errors)):\n",
        " if true_errors[x] >1*standard_deviation+ Mean:\n",
        "    indextracker.append(x)\n",
        "print(\"The anomalous points are at\" , indextracker)\n",
        "print(\"The total amount of anomalies is\", len(indextracker))"
      ],
      "metadata": {
        "id": "pHS9Adz-tUbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb6c825-7a43-46a4-c1b9-19a618f65723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The anomalous points are at [151, 439, 729, 1018, 1309, 1597, 1883, 2172, 2461, 3032, 3321, 3536, 3547, 3561, 3614, 3777, 3778, 3898]\n",
            "The total amount of anomalies is 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA2 = pd.read_csv(URL1)\n",
        "DATA2"
      ],
      "metadata": {
        "id": "Ppkwaqwgv5TD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9e1abfc8-a1db-402d-c3fa-e3887e65b796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                timestamp  value\n",
              "0     2014-02-14 14:30:00  0.132\n",
              "1     2014-02-14 14:35:00  0.134\n",
              "2     2014-02-14 14:40:00  0.134\n",
              "3     2014-02-14 14:45:00  0.134\n",
              "4     2014-02-14 14:50:00  0.134\n",
              "...                   ...    ...\n",
              "4027  2014-02-28 14:05:00  0.132\n",
              "4028  2014-02-28 14:10:00  0.134\n",
              "4029  2014-02-28 14:15:00  0.134\n",
              "4030  2014-02-28 14:20:00  0.134\n",
              "4031  2014-02-28 14:25:00  0.134\n",
              "\n",
              "[4032 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b609c028-df3f-4ce5-a3f9-049d777fbb7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014-02-14 14:30:00</td>\n",
              "      <td>0.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-02-14 14:35:00</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014-02-14 14:40:00</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014-02-14 14:45:00</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014-02-14 14:50:00</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4027</th>\n",
              "      <td>2014-02-28 14:05:00</td>\n",
              "      <td>0.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4028</th>\n",
              "      <td>2014-02-28 14:10:00</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4029</th>\n",
              "      <td>2014-02-28 14:15:00</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4030</th>\n",
              "      <td>2014-02-28 14:20:00</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4031</th>\n",
              "      <td>2014-02-28 14:25:00</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4032 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b609c028-df3f-4ce5-a3f9-049d777fbb7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b609c028-df3f-4ce5-a3f9-049d777fbb7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b609c028-df3f-4ce5-a3f9-049d777fbb7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d8caa101-6642-4163-a7a9-384c7e1491c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8caa101-6642-4163-a7a9-384c7e1491c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d8caa101-6642-4163-a7a9-384c7e1491c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "DATA2",
              "summary": "{\n  \"name\": \"DATA2\",\n  \"rows\": 4032,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 4032,\n        \"samples\": [\n          \"2014-02-18 13:20:00\",\n          \"2014-02-16 21:15:00\",\n          \"2014-02-16 22:20:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09481284708142514,\n        \"min\": 0.066,\n        \"max\": 2.344,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.602,\n          0.128,\n          0.14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(0,len(indextracker)):\n",
        "  print(DATA2.iloc[indextracker[x]]['timestamp'])"
      ],
      "metadata": {
        "id": "rf4lMALUvvOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced29aed-7a8b-41e5-a515-40fed9a9020f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2014-02-15 03:05:00\n",
            "2014-02-16 03:05:00\n",
            "2014-02-17 03:15:00\n",
            "2014-02-18 03:20:00\n",
            "2014-02-19 03:35:00\n",
            "2014-02-20 03:35:00\n",
            "2014-02-21 03:25:00\n",
            "2014-02-22 03:30:00\n",
            "2014-02-23 03:35:00\n",
            "2014-02-25 03:10:00\n",
            "2014-02-26 03:15:00\n",
            "2014-02-26 21:10:00\n",
            "2014-02-26 22:05:00\n",
            "2014-02-26 23:15:00\n",
            "2014-02-27 03:40:00\n",
            "2014-02-27 17:15:00\n",
            "2014-02-27 17:20:00\n",
            "2014-02-28 03:20:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " \"2014-02-26 22:05:00\",\n",
        "  \"2014-02-27 17:15:00\"\n",
        "\n",
        "  Both anomalies detected, 16 false positives."
      ],
      "metadata": {
        "id": "PWP0icUywLYN"
      }
    }
  ]
}